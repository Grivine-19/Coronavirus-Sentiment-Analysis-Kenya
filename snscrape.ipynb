{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snscrape.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMF4LwmzMaMD6VFJW+XroZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python38564bitbaseconda378a717c3d1e409e93df1db8692daf27",
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNb80A2ZufQF"
      },
      "source": [
        "# **<center>OVERVIEW</center>**\n",
        "\n",
        "> #### Here, I use snscrape as a library that allows us to fetch data without the limitations of tweepy, especially, after twitter rendered GetOldTweets3 obsolete due to change in its privacy policies.\n",
        "\n",
        "> #### Snscrape works only if you have the right version of Python installed. That is, Python 3.8 or higher.\n",
        "\n",
        "> #### At the time of writing this, it is more recommended to use the developer version of snscrape as it has more useful functionality.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYa7kFtYxXnP",
        "outputId": "4e3bfb0e-c0e8-4cdd-b200-eebcfac22408"
      },
      "source": [
        "#Download the developer version of snscrape\n",
        "#Do not use \"pip install snscrape\" as it does not give you the developer version of the library.\n",
        "#This version of snscrape cannot install on Google Colab Because colab uses python version 3.6. We require version 3.8 or higher for the task.\n",
        "#The solution is to run the command locally(local runtime environment on computer)\n",
        "\n",
        "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-85rwqher\n",
            "Requirement already satisfied (use --upgrade to upgrade): snscrape==0.3.5.dev95+g5cd3b7d from git+https://github.com/JustAnotherArchivist/snscrape.git in /home/grivine/anaconda3/lib/python3.8/site-packages\n",
            "Requirement already satisfied: requests[socks] in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (2.24.0)\n",
            "Requirement already satisfied: lxml in /home/grivine/.local/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (4.5.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (4.9.3)\n",
            "Requirement already satisfied: pytz in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (2020.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/grivine/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape==0.3.5.dev95+g5cd3b7d) (2.0.1)\n",
            "Building wheels for collected packages: snscrape\n",
            "  Building wheel for snscrape (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for snscrape: filename=snscrape-0.3.5.dev95+g5cd3b7d-py3-none-any.whl size=50122 sha256=7cdcadbaaaefcec539d10a8f04eb0bda5021e771c435058cc3b6284d36981c58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5qv6f5r7/wheels/92/42/87/33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
            "Successfully built snscrape\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#### To get the latitude and longitude of the cities in Kenya, I used this site; [LatLong.net](https://www.latlong.net/category/cities-115-15.html) for the geocode search parameter."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Importing required libraries for the task\n",
        "\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd \n",
        "\n",
        "# Creating list to append tweet data to\n",
        "\n",
        "tweets_list2 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('UhuruAddress geocode:-1.286389,36.817223,20km, since:2020-02-15 until:2020-07-31').get_items()):\n",
        "    if i>10:\n",
        "        tweets_list2.append([tweet.date, tweet.content, tweet.retweetCount, tweet.likeCount])\n",
        "\n",
        "#Removed: tweet.id, tweet.url, tweet.user.username\n",
        "    \n",
        "#Creating a dataframe from the tweets list above\n",
        "\n",
        "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime',  'Text', 'retweets', 'likes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Datetime  \\\n",
              "0 2020-06-06 19:28:03+00:00   \n",
              "1 2020-06-06 13:25:27+00:00   \n",
              "2 2020-06-06 13:24:27+00:00   \n",
              "3 2020-06-06 13:03:01+00:00   \n",
              "4 2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...         0      2  \n",
              "1  CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...         1     10  \n",
              "2  Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...         1      4  \n",
              "3  Fellow Kenyans #uhuruspeaks #UhuruAddress http...         0      1  \n",
              "4  #UhuruKenyatta Cessation of movement in Nairob...         0      2  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>Fellow Kenyans #uhuruspeaks #UhuruAddress http...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>#UhuruKenyatta Cessation of movement in Nairob...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Load the first few rows of the data frame \n",
        "\n",
        "tweets_df2.head()\n",
        "#tweets_df2.shape"
      ]
    },
    {
      "source": [
        "# <center> **DATA EXTRACTION PHASE** </center>\n",
        "\n",
        "#### Here we store the tweets fetched  in csv format and merge the results from different searches to make a singular dataset for Exploratory Data Analysis."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converting and storing the data in CSV format...:\nLoading the dataset's first few rows:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                   Datetime  \\\n",
              "0           0  2020-06-06 19:28:03+00:00   \n",
              "1           1  2020-06-06 13:25:27+00:00   \n",
              "2           2  2020-06-06 13:24:27+00:00   \n",
              "3           3  2020-06-06 13:03:01+00:00   \n",
              "4           4  2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...         0      2  \n",
              "1  CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...         1     10  \n",
              "2  Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...         1      4  \n",
              "3  Fellow Kenyans #uhuruspeaks #UhuruAddress http...         0      1  \n",
              "4  #UhuruKenyatta Cessation of movement in Nairob...         0      2  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>Fellow Kenyans #uhuruspeaks #UhuruAddress http...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>#UhuruKenyatta Cessation of movement in Nairob...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(\"converting and storing the data in CSV format...:\")\n",
        "\n",
        "tweets_df2.to_csv('nrb_address.csv')\n",
        "\n",
        "print(\"Loading the dataset's first few rows:\")\n",
        "\n",
        "df1 = pd.read_csv('nrb_address.csv')\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Merging the data from different search phrases\n",
        "\n",
        "data1=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_address.csv')\n",
        "data2=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_curfew.csv')\n",
        "data3=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_ke.csv')\n",
        "data4=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_komesha.csv')\n",
        "data5=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_lockdown.csv')\n",
        "data6=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_safe.csv')\n",
        "data7=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_tough.csv')\n",
        "\n",
        "nrb_merge_df = pd.concat([data1, data2, data3, data4, data5, data6, data7])\n",
        "\n",
        "#Converting to a csv file\n",
        "\n",
        "nrb_merge_df.to_csv('nairobi_county.csv')\n",
        "\n",
        "nairobi_df = pd.read_csv('nairobi_county.csv')"
      ]
    },
    {
      "source": [
        "# <center>**NAIROBI COUNTY EDA**</center>"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "#### Importing the libraries"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from plotly import graph_objs as go\n",
        "#from google.colab import drive from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1                   Datetime  \\\n",
              "0           0             0  2020-06-06 19:28:03+00:00   \n",
              "1           1             1  2020-06-06 13:25:27+00:00   \n",
              "2           2             2  2020-06-06 13:24:27+00:00   \n",
              "3           3             3  2020-06-06 13:03:01+00:00   \n",
              "4           4             4  2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...         0      2  \n",
              "1  CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...         1     10  \n",
              "2  Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...         1      4  \n",
              "3  Fellow Kenyans #uhuruspeaks #UhuruAddress http...         0      1  \n",
              "4  #UhuruKenyatta Cessation of movement in Nairob...         0      2  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>Fellow Kenyans #uhuruspeaks #UhuruAddress http...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>#UhuruKenyatta Cessation of movement in Nairob...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Load the first four rows of the data set\n",
        "\n",
        "nairobi_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1                   Datetime  \\\n",
              "8179          37            37  2020-05-29 06:20:25+00:00   \n",
              "8180          38            38  2020-05-29 06:03:22+00:00   \n",
              "8181          39            39  2020-05-29 05:19:20+00:00   \n",
              "8182          40            40  2020-05-27 18:59:53+00:00   \n",
              "8183          41            41  2020-05-27 18:54:16+00:00   \n",
              "\n",
              "                                                   Text  retweets  likes  \n",
              "8179  President Uhuru Kenyatta made it clear that's ...         0      2  \n",
              "8180  #Uhurustoughchoices Mlisema huyu Ni mtoto wa N...         0      0  \n",
              "8181  Among other tough choices Uhuru must make is g...         3      4  \n",
              "8182  Pandemic. Perforated pockets. Plunging economy...         1      6  \n",
              "8183  Pandemic. Perforated pockets. Plunging economy...        26     35  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8179</th>\n      <td>37</td>\n      <td>37</td>\n      <td>2020-05-29 06:20:25+00:00</td>\n      <td>President Uhuru Kenyatta made it clear that's ...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8180</th>\n      <td>38</td>\n      <td>38</td>\n      <td>2020-05-29 06:03:22+00:00</td>\n      <td>#Uhurustoughchoices Mlisema huyu Ni mtoto wa N...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8181</th>\n      <td>39</td>\n      <td>39</td>\n      <td>2020-05-29 05:19:20+00:00</td>\n      <td>Among other tough choices Uhuru must make is g...</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8182</th>\n      <td>40</td>\n      <td>40</td>\n      <td>2020-05-27 18:59:53+00:00</td>\n      <td>Pandemic. Perforated pockets. Plunging economy...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8183</th>\n      <td>41</td>\n      <td>41</td>\n      <td>2020-05-27 18:54:16+00:00</td>\n      <td>Pandemic. Perforated pockets. Plunging economy...</td>\n      <td>26</td>\n      <td>35</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "nairobi_df.tail()"
      ]
    },
    {
      "source": [
        "#### Shape of the Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8184, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#The number of rows and columns of the data\n",
        "\n",
        "nairobi_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0       int64\n",
              "Unnamed: 0.1     int64\n",
              "Datetime        object\n",
              "Text            object\n",
              "retweets         int64\n",
              "likes            int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Checking the data types of our data\n",
        "\n",
        "\"\"\" This is crucial for modeling tasks. e.g when solving a regression problem, we only deal with numerical data types and not categorical. \"\"\"\n",
        "\n",
        "nairobi_df.dtypes"
      ]
    },
    {
      "source": [
        "### **Cleaning the data**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "#### Dealing with missing values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0      0\n",
              "Unnamed: 0.1    0\n",
              "Datetime        0\n",
              "Text            0\n",
              "retweets        0\n",
              "likes           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#Checking for missing values\n",
        "\n",
        "\"\"\" If there are missing values in the columns, we either fill or drop them from the respective columns with too many missing values that are not of significance to the modeling task.\n",
        "\n",
        "For this case, there are no missing values to handle.\"\"\"\n",
        "\n",
        "nairobi_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "#Checking for duplicates\n",
        "print(nairobi_df.duplicated().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n(4214, 6)\n"
          ]
        }
      ],
      "source": [
        "#Dropping Duplicates\n",
        "\n",
        "nairobi_df.drop_duplicates(keep=False, inplace=True)\n",
        "\n",
        "#Confirming there are no duplicates\n",
        "\n",
        "print(nairobi_df.duplicated().any())\n",
        "print(nairobi_df.shape)"
      ]
    },
    {
      "source": [
        "#### Dealing with Outliers\n",
        "\n",
        "##### We check for outliers because often times, they result into an impbalanced data for modeling. i.e too many outliers bring about a high variance to our data. High variance causes overfitting to our model.\n",
        "\n",
        "##### A Z score is used since our dataset consists of more than 30 rows."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.14138055 0.0583916  0.0583916  ... 0.10758628 0.0583916  2.016332  ]\n"
          ]
        }
      ],
      "source": [
        "#Dealing with outliers\n",
        "#\n",
        "#Import stats from scipy library\n",
        "\n",
        "from scipy import stats\n",
        "num = ['retweets']\n",
        "for i, col in enumerate(num):\n",
        "    z = np.abs(stats.zscore(nairobi_df[col]))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous dataframe size : 4214\nNew dataframe size : 4173\n"
          ]
        }
      ],
      "source": [
        "#Confirming that our outliers have been dropped from the data set\n",
        "\n",
        "nairobi_df2 = nairobi_df[( z < 2 )]\n",
        "\n",
        "print(f\"Previous dataframe size : {nairobi_df.shape[0]}\" )\n",
        "print(f\"New dataframe size : {nairobi_df2.shape[0]}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  Unnamed: 0.1     retweets        likes\n",
              "count  4173.000000   4173.000000  4173.000000  4173.000000\n",
              "mean   1358.447160   1358.447160     0.938414     3.866044\n",
              "std    1011.783419   1011.783419     2.363796    11.782160\n",
              "min       0.000000      0.000000     0.000000     0.000000\n",
              "25%     444.000000    444.000000     0.000000     0.000000\n",
              "50%    1195.000000   1195.000000     0.000000     1.000000\n",
              "75%    2241.000000   2241.000000     1.000000     3.000000\n",
              "max    3298.000000   3298.000000    25.000000   202.000000"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4173.000000</td>\n      <td>4173.000000</td>\n      <td>4173.000000</td>\n      <td>4173.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1358.447160</td>\n      <td>1358.447160</td>\n      <td>0.938414</td>\n      <td>3.866044</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1011.783419</td>\n      <td>1011.783419</td>\n      <td>2.363796</td>\n      <td>11.782160</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>444.000000</td>\n      <td>444.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1195.000000</td>\n      <td>1195.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2241.000000</td>\n      <td>2241.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3298.000000</td>\n      <td>3298.000000</td>\n      <td>25.000000</td>\n      <td>202.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "nairobi_df2.describe()"
      ]
    },
    {
      "source": [
        "#### Cleaning the text"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unnamed: 0\nunnamed: 0.1\ndatetime\ntext\nretweets\nlikes\n"
          ]
        }
      ],
      "source": [
        "#Map the lowering function to all column names\n",
        "\n",
        "nairobi_df2.columns = map(str.lower, nairobi_df2.columns)\n",
        "\n",
        "#Print the column names\n",
        "\n",
        "for col in nairobi_df2:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Removing Whitespace from both columns and rows and converting case to lower case\n",
        "#\n",
        "#Converting the text column to string dtype after getting an attribute error\n",
        "\"\"\"nairobi_df2['text'] = nairobi_df2['text'].astype(str)\n",
        "\n",
        "nairobi_df2.columns = nairobi_df2.str.strip().str.replace(\",\").str.lower()\n",
        "\n",
        "cat = nairobi_df2['text']\n",
        "\n",
        "for i, c in enumerate(cat):\n",
        "    nairobi_df2[cat] = nairobi_df2[c].str.strip().str.replace(\",\").str.lower()\"\"\"\n",
        "\n",
        "#Make text lowercase, remove text in square brackets, remove links, remove punctuation and remove words containing numbers\n",
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(\"\\[.*?\\]\", '', text)\n",
        "    text = re.sub(\"https?://\\S+|www\\.S+\", '', text)\n",
        "    text = re.sub(\"<.*?>+\", '', text)\n",
        "    text = re.sub(\"[%s]\" % re.escape(string.punctuation) , '', text)\n",
        "    text = re.sub(\"\\n\", '', text)\n",
        "    text = re.sub(\"\\w*\\d\\w*\", '', text)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-8773a3d429ac>:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  nairobi_df2['text'] = nairobi_df2['text'].apply(lambda x:clean_text(x))\n"
          ]
        }
      ],
      "source": [
        "#Using a lambda function to clean the text column\n",
        "\n",
        "nairobi_df2['text'] = nairobi_df2['text'].apply(lambda x:clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      unnamed: 0  unnamed: 0.1                   datetime  \\\n",
              "8178          36            36  2020-05-29 06:34:32+00:00   \n",
              "8179          37            37  2020-05-29 06:20:25+00:00   \n",
              "8180          38            38  2020-05-29 06:03:22+00:00   \n",
              "8181          39            39  2020-05-29 05:19:20+00:00   \n",
              "8182          40            40  2020-05-27 18:59:53+00:00   \n",
              "\n",
              "                                                   text  retweets  likes  \n",
              "8178  theres nothing like making a tough choice when...         0      0  \n",
              "8179  president uhuru kenyatta made it clear thats t...         0      2  \n",
              "8180  uhurustoughchoices mlisema huyu ni mtoto wa na...         0      0  \n",
              "8181  among other tough choices uhuru must make is g...         3      4  \n",
              "8182  pandemic perforated pockets plunging economy p...         1      6  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unnamed: 0</th>\n      <th>unnamed: 0.1</th>\n      <th>datetime</th>\n      <th>text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8178</th>\n      <td>36</td>\n      <td>36</td>\n      <td>2020-05-29 06:34:32+00:00</td>\n      <td>theres nothing like making a tough choice when...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8179</th>\n      <td>37</td>\n      <td>37</td>\n      <td>2020-05-29 06:20:25+00:00</td>\n      <td>president uhuru kenyatta made it clear thats t...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8180</th>\n      <td>38</td>\n      <td>38</td>\n      <td>2020-05-29 06:03:22+00:00</td>\n      <td>uhurustoughchoices mlisema huyu ni mtoto wa na...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8181</th>\n      <td>39</td>\n      <td>39</td>\n      <td>2020-05-29 05:19:20+00:00</td>\n      <td>among other tough choices uhuru must make is g...</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8182</th>\n      <td>40</td>\n      <td>40</td>\n      <td>2020-05-27 18:59:53+00:00</td>\n      <td>pandemic perforated pockets plunging economy p...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#Preview the dataset to see changes\n",
        "\n",
        "nairobi_df2.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/grivine/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-37-5872c55b81a0>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  nairobi_df2['text_without_stopwords'] = nairobi_df2[\"text\"].apply(lambda words: ' '.join(word.lower() for word in words if word not in stop)) #this is a simpler way for not getting back a list of words\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unnamed: 0  unnamed: 0.1                   datetime  \\\n",
              "0           0             0  2020-06-06 19:28:03+00:00   \n",
              "1           1             1  2020-06-06 13:25:27+00:00   \n",
              "2           2             2  2020-06-06 13:24:27+00:00   \n",
              "3           3             3  2020-06-06 13:03:01+00:00   \n",
              "4           4             4  2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                text  retweets  likes  \\\n",
              "0  [mmetukosea, sana, sasa, ningeenda, hadi, paha...         0      2   \n",
              "1  [cant, wait, ðŸ¥°ðŸ¥°, blacklivesmatter, curfewinken...         1     10   \n",
              "2  [wakenya, hawachoki, na, meme, za, uhuruðŸ˜‚ðŸ˜‚, uh...         1      4   \n",
              "3       [fellow, kenyans, uhuruspeaks, uhuruaddress]         0      1   \n",
              "4  [uhurukenyatta, cessation, of, movement, in, n...         0      2   \n",
              "\n",
              "                              text_without_stopwords  \n",
              "0  mmetukosea sana sasa ningeenda hadi pahali gar...  \n",
              "1  cant wait ðŸ¥°ðŸ¥° blacklivesmatter curfewinkenya wa...  \n",
              "2  wakenya hawachoki na meme za uhuruðŸ˜‚ðŸ˜‚ uhurukeny...  \n",
              "3            fellow kenyans uhuruspeaks uhuruaddress  \n",
              "4  uhurukenyatta cessation movement nairobi momba...  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unnamed: 0</th>\n      <th>unnamed: 0.1</th>\n      <th>datetime</th>\n      <th>text</th>\n      <th>retweets</th>\n      <th>likes</th>\n      <th>text_without_stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>[mmetukosea, sana, sasa, ningeenda, hadi, paha...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>mmetukosea sana sasa ningeenda hadi pahali gar...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>[cant, wait, ðŸ¥°ðŸ¥°, blacklivesmatter, curfewinken...</td>\n      <td>1</td>\n      <td>10</td>\n      <td>cant wait ðŸ¥°ðŸ¥° blacklivesmatter curfewinkenya wa...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>[wakenya, hawachoki, na, meme, za, uhuruðŸ˜‚ðŸ˜‚, uh...</td>\n      <td>1</td>\n      <td>4</td>\n      <td>wakenya hawachoki na meme za uhuruðŸ˜‚ðŸ˜‚ uhurukeny...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>[fellow, kenyans, uhuruspeaks, uhuruaddress]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>fellow kenyans uhuruspeaks uhuruaddress</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>[uhurukenyatta, cessation, of, movement, in, n...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>uhurukenyatta cessation movement nairobi momba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#Removing Stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "nairobi_df2['text_without_stopwords'] = nairobi_df2[\"text\"].apply(lambda words: ' '.join(word.lower() for word in words if word not in stop)) #this is a simpler way for not getting back a list of words\n",
        "\n",
        "#nairobi_df2['text_without_stopwords'] = nairobi_df2['text'].apply(lambda x: ' '.join([word for word in x if word not in (stop)]))#this method gives back a list of words\n",
        "\n",
        "nairobi_df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data Available since 2020-02-16 11:30:23+00:00\n Data Available upto 2020-07-22 03:35:10+00:00\n"
          ]
        }
      ],
      "source": [
        "#Check for the maximum and minimum dates in the data\n",
        "\n",
        "print(f\" Data Available since {nairobi_df2.datetime.min()}\")\n",
        "print(f\" Data Available upto {nairobi_df2.datetime.max()}\")"
      ]
    },
    {
      "source": [
        "#### **Visualizations**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "#### Common Words"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-6626048f3037>:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  nairobi_df2['text_without_stopwords'] = nairobi_df2['text_without_stopwords'].apply(lambda x:str(x).split())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f336ae4dca0>"
            ],
            "text/html": "<style  type=\"text/css\" >\n#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row0_col1{\n            background-color:  #08306b;\n            color:  #f1f1f1;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row1_col1{\n            background-color:  #08519c;\n            color:  #f1f1f1;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row2_col1{\n            background-color:  #0b559f;\n            color:  #f1f1f1;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row3_col1{\n            background-color:  #b2d2e8;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row4_col1{\n            background-color:  #c9ddf0;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row5_col1{\n            background-color:  #d7e6f5;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row6_col1{\n            background-color:  #ddeaf7;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row7_col1{\n            background-color:  #dfebf7;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row8_col1,#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row9_col1{\n            background-color:  #e6f0f9;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row10_col1{\n            background-color:  #e7f0fa;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row11_col1{\n            background-color:  #ebf3fb;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row12_col1{\n            background-color:  #eef5fc;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row13_col1,#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row14_col1{\n            background-color:  #f2f7fd;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row15_col1{\n            background-color:  #f2f8fd;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row16_col1,#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row17_col1{\n            background-color:  #f3f8fe;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row18_col1,#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row19_col1{\n            background-color:  #f4f9fe;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row20_col1{\n            background-color:  #f5f9fe;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row21_col1{\n            background-color:  #f5fafe;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row22_col1{\n            background-color:  #f6faff;\n            color:  #000000;\n        }#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row23_col1,#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row24_col1,#T_7cb61bc4_8084_11eb_af1d_0d9105e89929row25_col1{\n            background-color:  #f7fbff;\n            color:  #000000;\n        }</style><table id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >common words</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row0_col0\" class=\"data row0 col0\" >stay</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row0_col1\" class=\"data row0 col1\" >1602</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row1_col0\" class=\"data row1 col0\" >safe</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row1_col1\" class=\"data row1 col1\" >1413</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row2_col0\" class=\"data row2 col0\" >staysafe</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row2_col1\" class=\"data row2 col1\" >1394</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row3_col0\" class=\"data row3 col0\" >curfewinkenya</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row3_col1\" class=\"data row3 col1\" >593</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row4_col0\" class=\"data row4 col0\" >stayhome</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row4_col1\" class=\"data row4 col1\" >472</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row5_col0\" class=\"data row5 col0\" >home</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row5_col1\" class=\"data row5 col1\" >365</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row6_col0\" class=\"data row6 col0\" >us</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row6_col1\" class=\"data row6 col1\" >319</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row7\" class=\"row_heading level0 row7\" >7</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row7_col0\" class=\"data row7 col0\" >nairobi</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row7_col1\" class=\"data row7 col1\" >306</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row8\" class=\"row_heading level0 row8\" >8</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row8_col0\" class=\"data row8 col0\" >amp</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row8_col1\" class=\"data row8 col1\" >255</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row9\" class=\"row_heading level0 row9\" >9</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row9_col0\" class=\"data row9 col0\" >kenya</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row9_col1\" class=\"data row9 col1\" >253</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row10\" class=\"row_heading level0 row10\" >10</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row10_col0\" class=\"data row10 col0\" >happy</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row10_col1\" class=\"data row10 col1\" >248</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row11\" class=\"row_heading level0 row11\" >11</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row11_col0\" class=\"data row11 col0\" >good</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row11_col1\" class=\"data row11 col1\" >213</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row12\" class=\"row_heading level0 row12\" >12</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row12_col0\" class=\"data row12 col0\" >people</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row12_col1\" class=\"data row12 col1\" >196</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row13\" class=\"row_heading level0 row13\" >13</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row13_col0\" class=\"data row13 col0\" >corona</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row13_col1\" class=\"data row13 col1\" >172</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row14\" class=\"row_heading level0 row14\" >14</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row14_col0\" class=\"data row14 col0\" >day</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row14_col1\" class=\"data row14 col1\" >171</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row15\" class=\"row_heading level0 row15\" >15</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row15_col0\" class=\"data row15 col0\" >keep</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row15_col1\" class=\"data row15 col1\" >166</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row16\" class=\"row_heading level0 row16\" >16</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row16_col0\" class=\"data row16 col0\" >time</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row16_col1\" class=\"data row16 col1\" >158</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row17\" class=\"row_heading level0 row17\" >17</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row17_col0\" class=\"data row17 col0\" >new</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row17_col1\" class=\"data row17 col1\" >157</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row18\" class=\"row_heading level0 row18\" >18</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row18_col0\" class=\"data row18 col0\" >sanitize</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row18_col1\" class=\"data row18 col1\" >153</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row19\" class=\"row_heading level0 row19\" >19</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row19_col0\" class=\"data row19 col0\" >stayathome</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row19_col1\" class=\"data row19 col1\" >152</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row20\" class=\"row_heading level0 row20\" >20</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row20_col0\" class=\"data row20 col0\" >curfew</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row20_col1\" class=\"data row20 col1\" >147</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row21\" class=\"row_heading level0 row21\" >21</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row21_col0\" class=\"data row21 col0\" >get</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row21_col1\" class=\"data row21 col1\" >141</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row22\" class=\"row_heading level0 row22\" >22</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row22_col0\" class=\"data row22 col0\" >kenyans</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row22_col1\" class=\"data row22 col1\" >132</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row23\" class=\"row_heading level0 row23\" >23</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row23_col0\" class=\"data row23 col0\" >please</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row23_col1\" class=\"data row23 col1\" >131</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row24\" class=\"row_heading level0 row24\" >24</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row24_col0\" class=\"data row24 col0\" >lockdown</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row24_col1\" class=\"data row24 col1\" >130</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929level0_row25\" class=\"row_heading level0 row25\" >25</th>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row25_col0\" class=\"data row25 col0\" >call</td>\n                        <td id=\"T_7cb61bc4_8084_11eb_af1d_0d9105e89929row25_col1\" class=\"data row25 col1\" >126</td>\n            </tr>\n    </tbody></table>"
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#Checking for the most common words\n",
        "\n",
        "from collections import Counter\n",
        "nairobi_df2['text_without_stopwords'] = nairobi_df2['text_without_stopwords'].apply(lambda x:str(x).split())\n",
        "top = Counter([item for sublist in nairobi_df2['text_without_stopwords'] for item in sublist])\n",
        "tweets = pd.DataFrame(top.most_common(26))\n",
        "tweets.columns = ['common words', 'count']\n",
        "tweets.style.background_gradient(cmap = 'Blues')"
      ]
    },
    {
      "source": [
        "#### Word Cloud"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "#for dirname, _, filenames in os.walk('/home/grivine/Desktop/Get_Old_Tweets_Approach'):\n",
        "    #for filename in filenames:\n",
        "        #print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'STOPWORDS' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-22fbf1d4683a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#Wordcloud for the  train text_without_stopwords column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplot_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnairobi_df2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_without_stopwords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-22fbf1d4683a>\u001b[0m in \u001b[0;36mplot_wordcloud\u001b[0;34m(text_without_stopwords, mask, max_words, max_font_size, figure_size, color, title, title_size, image_color)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#stopwords = set(stopwords.words('english'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmore_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmore_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'STOPWORDS' is not defined"
          ]
        }
      ],
      "source": [
        "def plot_wordcloud(text_without_stopwords, mask = None, max_words = 200, max_font_size = 100, figure_size = (24.0,16.0), color = 'white', title = 'Coronavirus Perception in Nairobi,Kenya', title_size = 40, image_color = False):\n",
        "    \n",
        "    #stopwords = set(stopwords.words('english'))\n",
        "    stopwords = set(STOPWORDS.words('english'))\n",
        "    more_stopwords = ('for', 'to')\n",
        "    stopwords = stopwords.union(more_stopwords)\n",
        "\n",
        "    wordcloud = wordcloud(background_color = color,\n",
        "    stopwords = stopwords, max_words = max_words, max_font_size = max_font_size,\n",
        "    random_state = 42, width = 400, height = 200, mask = mask)\n",
        "    wordcloud.generate(str(text_without_stopwords)) \n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    if image_color:\n",
        "        image_colors = ImageColorGenerator(mask)\n",
        "        plt.imshow(wordcloud.recolor(color_func = image_colors), interpolation = 'bilinear')\n",
        "        plt.title(title, fontdict={'size': 'font_size', 'verticalalignment': 'bottom'})\n",
        "    else:\n",
        "        plt.imshow(wordcloud)\n",
        "        plt.title(title, fontdict={'size': 'font_size', 'color': 'black', 'verticalalignment': 'bottom'})\n",
        "        \n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "d = '/home/grivine/Desktop/Get_Old_Tweets_Approach'\n",
        "\n",
        "#Wordcloud for the  train text_without_stopwords column\n",
        "\n",
        "plot_wordcloud(nairobi_df2['text_without_stopwords'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}