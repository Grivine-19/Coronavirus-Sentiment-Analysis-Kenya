{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snscrape.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMF4LwmzMaMD6VFJW+XroZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python38564bitbaseconda378a717c3d1e409e93df1db8692daf27",
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Grivine-19/Coronavirus-Sentiment-Analysis-Kenya/blob/development/snscrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBzCffokr3_i"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNb80A2ZufQF"
      },
      "source": [
        "**<center>OVERVIEW</center>**\n",
        "\n",
        "> Here, I use snscrape as a library that allows us to fetch data without the limitations of tweepy, especially, after twitter rendered GetOldTweets3 obsolete due to change in its privacy policies.\n",
        "\n",
        "> Snscrape works only if you have the right version of Python installed. That is, Python 3.8 or higher.\n",
        "\n",
        "> At the time of writing this, it is more recommended to use the developer version of snscrape as it has more useful functionality.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYa7kFtYxXnP",
        "outputId": "4e3bfb0e-c0e8-4cdd-b200-eebcfac22408"
      },
      "source": [
        "#Download the developer version of snscrape\n",
        "#Do not use \"pip install snscrape\" as it does not give you the developer version of the library.\n",
        "#This version of snscrape cannot install on Google Colab Because colab uses python version 3.6. We require version 3.8 or higher for the task.\n",
        "#The solution is to run the command locally(local runtime environment on computer)\n",
        "\n",
        "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-85rwqher\n",
            "Requirement already satisfied (use --upgrade to upgrade): snscrape==0.3.5.dev95+g5cd3b7d from git+https://github.com/JustAnotherArchivist/snscrape.git in /home/grivine/anaconda3/lib/python3.8/site-packages\n",
            "Requirement already satisfied: requests[socks] in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (2.24.0)\n",
            "Requirement already satisfied: lxml in /home/grivine/.local/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (4.5.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (4.9.3)\n",
            "Requirement already satisfied: pytz in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (2020.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/grivine/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape==0.3.5.dev95+g5cd3b7d) (2.0.1)\n",
            "Building wheels for collected packages: snscrape\n",
            "  Building wheel for snscrape (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for snscrape: filename=snscrape-0.3.5.dev95+g5cd3b7d-py3-none-any.whl size=50122 sha256=7cdcadbaaaefcec539d10a8f04eb0bda5021e771c435058cc3b6284d36981c58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5qv6f5r7/wheels/92/42/87/33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
            "Successfully built snscrape\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#### To get the latitude and longitude of the cities in Kenya, I used this site; [LatLong.net](https://www.latlong.net/category/cities-115-15.html) for the geocode search parameter."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Importing required libraries for the task\n",
        "\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd \n",
        "\n",
        "# Creating list to append tweet data to\n",
        "\n",
        "tweets_list2 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('KomeshaCorona geocode:-1.286389,36.817223,20km, since:2020-02-15 until:2020-07-31').get_items()):\n",
        "    if i>100:\n",
        "        tweets_list2.append([tweet.date, tweet.content, tweet.retweetCount, tweet.likeCount])\n",
        "\n",
        "#Removed: tweet.id, tweet.url, tweet.user.username\n",
        "    \n",
        "#Creating a dataframe from the tweets list above\n",
        "\n",
        "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime',  'Text', 'retweets', 'likes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Datetime  \\\n",
              "0 2020-06-23 14:22:56+00:00   \n",
              "1 2020-06-23 08:56:53+00:00   \n",
              "2 2020-06-23 08:45:31+00:00   \n",
              "3 2020-06-22 11:44:45+00:00   \n",
              "4 2020-06-22 11:15:23+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  ChildFund has supported Ministry of Health wit...         1      2  \n",
              "1  If she's into arguing just know that she want ...         0      0  \n",
              "2  Back To Work After\" Covid Vacation\"\\nI have no...         0      4  \n",
              "3  https://t.co/6tOgHioXNJ #KomeshaCorona #COVID19KE         0      0  \n",
              "4  Working from @LatticeOffice Personal starter p...         3      6  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-23 14:22:56+00:00</td>\n      <td>ChildFund has supported Ministry of Health wit...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-23 08:56:53+00:00</td>\n      <td>If she's into arguing just know that she want ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-23 08:45:31+00:00</td>\n      <td>Back To Work After\" Covid Vacation\"\\nI have no...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-22 11:44:45+00:00</td>\n      <td>https://t.co/6tOgHioXNJ #KomeshaCorona #COVID19KE</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-22 11:15:23+00:00</td>\n      <td>Working from @LatticeOffice Personal starter p...</td>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Load the first few rows of the data frame \n",
        "\n",
        "tweets_df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}