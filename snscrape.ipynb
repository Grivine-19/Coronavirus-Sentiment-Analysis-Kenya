{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snscrape.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMF4LwmzMaMD6VFJW+XroZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python38564bitbaseconda378a717c3d1e409e93df1db8692daf27",
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNb80A2ZufQF"
      },
      "source": [
        "# **<center>OVERVIEW</center>**\n",
        "\n",
        "> #### Here, I use snscrape as a library that allows us to fetch data without the limitations of tweepy, especially, after twitter rendered GetOldTweets3 obsolete due to change in its privacy policies.\n",
        "\n",
        "> #### Snscrape works only if you have the right version of Python installed. That is, Python 3.8 or higher.\n",
        "\n",
        "> #### At the time of writing this, it is more recommended to use the developer version of snscrape as it has more useful functionality.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYa7kFtYxXnP",
        "outputId": "4e3bfb0e-c0e8-4cdd-b200-eebcfac22408"
      },
      "source": [
        "#Download the developer version of snscrape\n",
        "#Do not use \"pip install snscrape\" as it does not give you the developer version of the library.\n",
        "#This version of snscrape cannot install on Google Colab Because colab uses python version 3.6. We require version 3.8 or higher for the task.\n",
        "#The solution is to run the command locally(local runtime environment on computer)\n",
        "\n",
        "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-85rwqher\n",
            "Requirement already satisfied (use --upgrade to upgrade): snscrape==0.3.5.dev95+g5cd3b7d from git+https://github.com/JustAnotherArchivist/snscrape.git in /home/grivine/anaconda3/lib/python3.8/site-packages\n",
            "Requirement already satisfied: requests[socks] in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (2.24.0)\n",
            "Requirement already satisfied: lxml in /home/grivine/.local/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (4.5.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (4.9.3)\n",
            "Requirement already satisfied: pytz in /home/grivine/anaconda3/lib/python3.8/site-packages (from snscrape==0.3.5.dev95+g5cd3b7d) (2020.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/grivine/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev95+g5cd3b7d) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/grivine/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape==0.3.5.dev95+g5cd3b7d) (2.0.1)\n",
            "Building wheels for collected packages: snscrape\n",
            "  Building wheel for snscrape (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for snscrape: filename=snscrape-0.3.5.dev95+g5cd3b7d-py3-none-any.whl size=50122 sha256=7cdcadbaaaefcec539d10a8f04eb0bda5021e771c435058cc3b6284d36981c58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5qv6f5r7/wheels/92/42/87/33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
            "Successfully built snscrape\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#### To get the latitude and longitude of the cities in Kenya, I used this site; [LatLong.net](https://www.latlong.net/category/cities-115-15.html) for the geocode search parameter."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Importing required libraries for the task\n",
        "\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd \n",
        "\n",
        "# Creating list to append tweet data to\n",
        "\n",
        "tweets_list2 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('UhuruAddress geocode:-1.286389,36.817223,20km, since:2020-02-15 until:2020-07-31').get_items()):\n",
        "    if i>10:\n",
        "        tweets_list2.append([tweet.date, tweet.content, tweet.retweetCount, tweet.likeCount])\n",
        "\n",
        "#Removed: tweet.id, tweet.url, tweet.user.username\n",
        "    \n",
        "#Creating a dataframe from the tweets list above\n",
        "\n",
        "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime',  'Text', 'retweets', 'likes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Datetime  \\\n",
              "0 2020-06-06 19:28:03+00:00   \n",
              "1 2020-06-06 13:25:27+00:00   \n",
              "2 2020-06-06 13:24:27+00:00   \n",
              "3 2020-06-06 13:03:01+00:00   \n",
              "4 2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...         0      2  \n",
              "1  CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...         1     10  \n",
              "2  Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...         1      4  \n",
              "3  Fellow Kenyans #uhuruspeaks #UhuruAddress http...         0      1  \n",
              "4  #UhuruKenyatta Cessation of movement in Nairob...         0      2  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>Fellow Kenyans #uhuruspeaks #UhuruAddress http...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>#UhuruKenyatta Cessation of movement in Nairob...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "#Load the first few rows of the data frame \n",
        "\n",
        "tweets_df2.head()\n",
        "#tweets_df2.shape"
      ]
    },
    {
      "source": [
        "# <center> **DATA EXTRACTION PHASE** </center>\n",
        "\n",
        "#### Here we store the tweets fetched  in csv format and merge the results from different searches to make a singular dataset for Exploratory Data Analysis."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converting and storing the data in CSV format...:\nLoading the dataset's first few rows:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                   Datetime  \\\n",
              "0           0  2020-06-06 19:28:03+00:00   \n",
              "1           1  2020-06-06 13:25:27+00:00   \n",
              "2           2  2020-06-06 13:24:27+00:00   \n",
              "3           3  2020-06-06 13:03:01+00:00   \n",
              "4           4  2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...         0      2  \n",
              "1  CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...         1     10  \n",
              "2  Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...         1      4  \n",
              "3  Fellow Kenyans #uhuruspeaks #UhuruAddress http...         0      1  \n",
              "4  #UhuruKenyatta Cessation of movement in Nairob...         0      2  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>Fellow Kenyans #uhuruspeaks #UhuruAddress http...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>#UhuruKenyatta Cessation of movement in Nairob...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "print(\"converting and storing the data in CSV format...:\")\n",
        "\n",
        "tweets_df2.to_csv('nrb_address.csv')\n",
        "\n",
        "print(\"Loading the dataset's first few rows:\")\n",
        "\n",
        "df1 = pd.read_csv('nrb_address.csv')\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Merging the data from different search phrases\n",
        "\n",
        "data1=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_address.csv')\n",
        "data2=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_curfew.csv')\n",
        "data3=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_ke.csv')\n",
        "data4=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_komesha.csv')\n",
        "data5=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_lockdown.csv')\n",
        "data6=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_safe.csv')\n",
        "data7=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets_Approach/nrb_tough.csv')\n",
        "\n",
        "nrb_merge_df = pd.concat([data1, data2, data3, data4, data5, data6, data7])\n",
        "\n",
        "#Converting to a csv file\n",
        "\n",
        "nrb_merge_df.to_csv('nairobi_county.csv')\n",
        "\n",
        "nairobi_df = pd.read_csv('nairobi_county.csv')"
      ]
    },
    {
      "source": [
        "# <center>**NAIROBI COUNTY EDA**</center>"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "#### Importing the libraries"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from plotly import graph_objs as go\n",
        "#from google.colab import drive from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Datetime  \\\n",
              "0  2020-06-06 19:28:03+00:00   \n",
              "1  2020-06-06 13:25:27+00:00   \n",
              "2  2020-06-06 13:24:27+00:00   \n",
              "3  2020-06-06 13:03:01+00:00   \n",
              "4  2020-06-06 13:02:49+00:00   \n",
              "\n",
              "                                                Text  retweets  likes  \n",
              "0  Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...         0      2  \n",
              "1  CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...         1     10  \n",
              "2  Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...         1      4  \n",
              "3  Fellow Kenyans #uhuruspeaks #UhuruAddress http...         0      1  \n",
              "4  #UhuruKenyatta Cessation of movement in Nairob...         0      2  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-06 19:28:03+00:00</td>\n      <td>Mmetukosea sana! \\n\\nSasa ningeenda hadi pahal...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-06 13:25:27+00:00</td>\n      <td>CAN'T WAIT ðŸ¥°ðŸ¥° #6thjune #BlackLivesMatter #Curf...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-06 13:24:27+00:00</td>\n      <td>Wakenya hawachoki na meme za UhuruðŸ˜‚ðŸ˜‚ #UhuruKen...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-06 13:03:01+00:00</td>\n      <td>Fellow Kenyans #uhuruspeaks #UhuruAddress http...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-06 13:02:49+00:00</td>\n      <td>#UhuruKenyatta Cessation of movement in Nairob...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "#Load the first four rows of the data set\n",
        "\n",
        "nairobi_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Datetime  \\\n",
              "8179  2020-05-29 06:20:25+00:00   \n",
              "8180  2020-05-29 06:03:22+00:00   \n",
              "8181  2020-05-29 05:19:20+00:00   \n",
              "8182  2020-05-27 18:59:53+00:00   \n",
              "8183  2020-05-27 18:54:16+00:00   \n",
              "\n",
              "                                                   Text  retweets  likes  \n",
              "8179  President Uhuru Kenyatta made it clear that's ...         0      2  \n",
              "8180  #Uhurustoughchoices Mlisema huyu Ni mtoto wa N...         0      0  \n",
              "8181  Among other tough choices Uhuru must make is g...         3      4  \n",
              "8182  Pandemic. Perforated pockets. Plunging economy...         1      6  \n",
              "8183  Pandemic. Perforated pockets. Plunging economy...        26     35  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Text</th>\n      <th>retweets</th>\n      <th>likes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8179</th>\n      <td>2020-05-29 06:20:25+00:00</td>\n      <td>President Uhuru Kenyatta made it clear that's ...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8180</th>\n      <td>2020-05-29 06:03:22+00:00</td>\n      <td>#Uhurustoughchoices Mlisema huyu Ni mtoto wa N...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8181</th>\n      <td>2020-05-29 05:19:20+00:00</td>\n      <td>Among other tough choices Uhuru must make is g...</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8182</th>\n      <td>2020-05-27 18:59:53+00:00</td>\n      <td>Pandemic. Perforated pockets. Plunging economy...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8183</th>\n      <td>2020-05-27 18:54:16+00:00</td>\n      <td>Pandemic. Perforated pockets. Plunging economy...</td>\n      <td>26</td>\n      <td>35</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "nairobi_df.tail()"
      ]
    },
    {
      "source": [
        "#### Shape of the Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8184, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "#The number of rows and columns of the data\n",
        "\n",
        "nairobi_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datetime    object\n",
              "Text        object\n",
              "retweets     int64\n",
              "likes        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "#Checking the data types of our data\n",
        "\n",
        "\"\"\" This is crucial for modeling tasks. e.g when solving a regression problem, we only deal with numerical data types and not categorical. \"\"\"\n",
        "\n",
        "nairobi_df.dtypes"
      ]
    },
    {
      "source": [
        "### **Cleaning the data**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "#### Dealing with missing values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datetime    0\n",
              "Text        0\n",
              "retweets    0\n",
              "likes       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "#Checking for missing values\n",
        "\n",
        "\"\"\" If there are missing values in the columns, we either fill or drop them from the respective columns with too many missing values that are not of significance to the modeling task.\n",
        "\n",
        "For this case, there are no missing values to handle.\"\"\"\n",
        "\n",
        "nairobi_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "#Checking for duplicates\n",
        "print(nairobi_df.duplicated().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n(4014, 4)\n"
          ]
        }
      ],
      "source": [
        "#Dropping Duplicates\n",
        "\n",
        "nairobi_df.drop_duplicates(keep=False, inplace=True)\n",
        "\n",
        "#Confirming there are no duplicates\n",
        "\n",
        "print(nairobi_df.duplicated().any())\n",
        "print(nairobi_df.shape)"
      ]
    },
    {
      "source": [
        "#### Dealing with Outliers\n",
        "\n",
        "##### We check for outliers because often times, they result into an impbalanced data for modeling. i.e too many outliers bring about a high variance to our data. High variance causes overfitting to our model.\n",
        "\n",
        "##### A Z score is used since our dataset consists of more than 30 rows."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.13729457 0.05489319 0.13729457 ... 0.10990955 0.05489319 2.00514114]\n"
          ]
        }
      ],
      "source": [
        "#Dealing with outliers\n",
        "#\n",
        "#Import stats from scipy library\n",
        "\n",
        "from scipy import stats\n",
        "num = ['retweets']\n",
        "for i, col in enumerate(num):\n",
        "    z = np.abs(stats.zscore(nairobi_df[col]))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous dataframe size : 4014\nNew dataframe size : 4014\n"
          ]
        }
      ],
      "source": [
        "#Confirming that our outliers have been dropped from the data set\n",
        "\n",
        "nairobi_df2 = nairobi_df[( z < 2 )]\n",
        "\n",
        "print(f\"Previous dataframe size : {nairobi_df.shape[0]}\" )\n",
        "print(f\"New dataframe size : {nairobi_df.shape[0]}\" )"
      ]
    },
    {
      "source": [
        "#### Cleaning the text"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data Available since 2020-02-16 11:30:23+00:00\n Data Available upto 2020-07-22 03:35:10+00:00\n"
          ]
        }
      ],
      "source": [
        "#Check for the maximum and minimum dates in the data\n",
        "\n",
        "print(f\" Data Available since {nairobi_df.Datetime.min()}\")\n",
        "print(f\" Data Available upto {nairobi_df.Datetime.max()}\")"
      ]
    }
  ]
}