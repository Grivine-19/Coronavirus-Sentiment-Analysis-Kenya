{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda378a717c3d1e409e93df1db8692daf27",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# <center>Coronavirus Sentiment Analysis(Kenya)</center>\n",
    "\n",
    "<img src=\"https://images.unsplash.com/photo-1584118624012-df056829fbd0?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=500&q=60\" alt=\"Credits: CDC on Unsplash\" width=\"950\"\n",
    "         height=\"350\">\n",
    "\n",
    "## **Project Objective**\n",
    "* To determine change in sentiment/perception over time on COVID-19 across different regions in the country(Kenya)\n",
    "\n",
    "*The regions to be covered include:*\n",
    "\n",
    "1. *Nairobi*\n",
    "2. *Mombasa*\n",
    "3. *Migori*\n",
    "4. *Kiambu*\n",
    "5. *Mandera*\n",
    "\n",
    "*Timespan: 2019-11-01 to 2020-08-01*\n",
    "\n",
    "## **Sources of Data**\n",
    "* Twitter\n",
    "\n",
    "*Search Phrases to look out for include popular hashtags such as:*\n",
    "\n",
    "1. *#KomeshaCorona*\n",
    "2. *#COVID19KE*\n",
    "3. *#UHURUsToughChoices*\n",
    "4. *#UhuruAddress*\n",
    "5. *#staysafe*\n",
    "\n",
    "### *For the rest of the towns/counties, different hashtags were used as indicated below:*\n",
    "\n",
    "#### Mombasa:\n",
    "\n",
    "* *COVID_19*\n",
    "\n",
    "#### Migori:\n",
    "*  *COVID_19*\n",
    "\n",
    "#### Kiambu:\n",
    "* *COVID_19*\n",
    "\n",
    "*Number of tweets to fetch per region = 100000*\n",
    "\n",
    "## **Tools**\n",
    "1. Google Colab\n",
    "2. Github\n",
    "3. Python and its relevant frameworks\n",
    "4. Docker **NB: will dockerize the project at the end**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# **<center>Issues Arising From Tweepy Approach</center>**\n",
    "\n",
    "1. ### Tweepy Limitations\n",
    "\n",
    "* *There are different types and levels of API access(**Standard, Premium and Enterprise**) that tweepy offers for very specific use-cases. For my case, I was using the Standard API access for a free Twitter Developers Account*\n",
    "   * The standard API only allows you to scape tweets upto seven(7) days old\n",
    "\n",
    "   * Limited to scraping only 15K tweets per 15min window. This can however be increased through [these methods](https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./).\n",
    "\n",
    "   * Can only obtain a max of 3200 tweets of users most recent tweet.\n",
    "\n",
    "   * Suitable when making complex queries or extensive information for each tweet is needed.\n",
    "   \n",
    "2. ### Search Context\n",
    "* *Could not maintain a search context across our API rate limit window, so as to avoid getting duplicate results when searching repeatedly over a long period of time*\n",
    "\n",
    "* *the fact that not all tweets matching the search criteria will be returned by the API*\n",
    "\n",
    "\n",
    "# **<center>Adopted APproach</center>**\n",
    "\n",
    "**GetOldtweets3**\n",
    "**Snscrape(developer version)**\n",
    "\n",
    "*Both package allow me to work around Twitters Standard API limitations and is a quick, no frills way of scraping.*\n",
    "\n",
    "*GetOldtweets3 is however said to be rendered obsolete after twitter changed its privacy policy late in the year, 2020*\n",
    "\n",
    "*Does not offer extensive functionality like tweepy.*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Aditional Resources:** *Reading material*\n",
    "\n",
    "#### [Tweets by location using Snscrape](https://medium.com/swlh/how-to-scrape-tweets-by-location-in-python-using-snscrape-8c870fa6ec25)\n",
    "\n",
    "#### [Twiter advanced search-Snscrape](https://github.com/igorbrigadir/twitter-advanced-search)\n",
    "\n",
    "#### [How to scrape Tweets using Snscrape](https://betterprogramming.pub/how-to-scrape-tweets-with-snscrape-90124ed006af)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}