{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit0854bf3467af411fb37e49bb5515948a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Coronavirus Sentiment Analysis(Kenya)</center>\n",
    "\n",
    "<img src=\"https://images.unsplash.com/photo-1584118624012-df056829fbd0?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=500&q=60\" alt=\"Credits: CDC on Unsplash\" width=\"950\"\n",
    "         height=\"350\">\n",
    "\n",
    "## **Project Objective**\n",
    "* To determine change in sentiment/perception over time on COVID-19 across different regions in the country(Kenya)\n",
    "\n",
    "*The regions to be covered include:*\n",
    "\n",
    "1. *Nairobi*\n",
    "2. *Mombasa*\n",
    "3. *Migori*\n",
    "4. *Kiambu*\n",
    "5. *Mandera*\n",
    "\n",
    "*Timespan: 2019-11-01 to 2020-08-01*\n",
    "\n",
    "## **Sources of Data**\n",
    "* Twitter\n",
    "\n",
    "*Search Phrases to look out for include popular hashtags such as:*\n",
    "\n",
    "1. *#KomeshaCorona*\n",
    "2. *#COVID19KE*\n",
    "3. *#UHURUsToughChoices*\n",
    "4. *#UhuruAddress*\n",
    "5. *#staysafe*\n",
    "\n",
    "*Number of tweets to fetch per region = 100000*\n",
    "\n",
    "## **Tools**\n",
    "1. Google Colab\n",
    "2. Github\n",
    "3. Python and its relevant frameworks\n",
    "4. Docker **NB: will dockerize the project at the end**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Issues Arising From Tweepy Approach</center>**\n",
    "\n",
    "1. ### Tweepy Limitations\n",
    "\n",
    "* *There are different types and levels of API access(**Standard, Premium and Enterprise**) that tweepy offers for very specific use-cases. For my case, I was using the Standard API access for a free Twitter Developers Account*\n",
    "   * The standard API only allows you to scape tweets upto seven(7) days old\n",
    "\n",
    "   * Limited to scraping only 15K tweets per 15min window. This can however be increased through [these methods](https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./).\n",
    "\n",
    "   * Can only obtain a max of 3200 tweets of users most recent tweet.\n",
    "\n",
    "   * Suitable when making complex queries or extensive information for each tweet is needed.\n",
    "   \n",
    "2. ### Search Context\n",
    "* *Could not maintain a search context across our API rate limit window, so as to avoid getting duplicate results when searching repeatedly over a long period of time*\n",
    "\n",
    "* *the fact that not all tweets matching the search criteria will be returned by the API*\n",
    "\n",
    "\n",
    "# **<center>Adopted APproach; GetOldTweets3</center>**\n",
    "\n",
    "*The package allows me to work around Twitters Standard API limitations and is a quick, no frills way of scraping.*\n",
    "\n",
    "*Does not offer extensive functionality like tweepy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define global variables for the project\n",
    "\n",
    "'''the phrase to search for \n",
    "Can only search for string, not list or otherwise\n",
    "#Search words below were used only for the case of Nairobi\n",
    "#KomeshaCorona\n",
    "#COVID19KE\n",
    "#UHURUsToughChoices\n",
    "#UhuruAddress\n",
    "#staysafe\n",
    "#UhuruDontLiftLockdown\n",
    "#CurfewinKenya'''\n",
    "\n",
    "search_text = 'COVID_19'  \n",
    "\n",
    "since_date = '2019-11-01' #specifies the date to begin querying/searching from\n",
    "\n",
    "until_date = '2020-08-01' #specifies the date to end our query/search\n",
    "\n",
    "count = 100000 #specifies the number of tweets to fetch. Give a high value figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *For the rest of the towns/counties, different hashtags were used as indicated below:*\n",
    "\n",
    "### Mombasa:\n",
    "\n",
    "* *COVID_19*\n",
    "\n",
    "### Migori:\n",
    "*  *COVID_19*\n",
    "\n",
    "### Kiambu:\n",
    "* *COVID_19*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Creation of a Query Object**</center>\n",
    "\n",
    "#### *I will be using python classes; tweet, tweetManager and tweetCriteria of the GetOldTweets Library*\n",
    "\n",
    "#### *The search parameters to look out for that suit my purpose in this project are:*\n",
    "* *Text of the tweet*\n",
    "* *Location of the user-doesn't give the precise location of the tweet but a general location of the tweet since most users do not share the exact tweet location*\n",
    "* *Date of the tweet*\n",
    "* *Retweet Count-shows that most people resonate with the tweet*\n",
    "* *Favorited tweets*\n",
    "* *Hashtag-our search_text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Execute the code using python classes\n",
    "\n",
    "#search parameters to be used with the manager class\n",
    "\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(search_text).setSince(since_date)\\\n",
    "    .setUntil(until_date).setNear('Mombasa,Kenya').setMaxTweets(count)\n",
    "\n",
    "#List of objects get stored in tweets variable\n",
    "\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "#print(tweets + '\\n')\n",
    "\n",
    "#iterating through tweets list and storing them temporarily in the tweets variable.\n",
    "#get information and store it as a list inside tweetsList\n",
    "\n",
    "tweetList = [[tweet.id, tweet.date, tweet.text, tweet.geo, tweet.retweets, tweet.favorites, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "#print(tweetList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the columns for your dataframe\n",
    "\n",
    "columns_new = ['ID', 'DATE', 'TWEET', 'LOCATION', 'RETWEETS', 'FAVORITES', 'HASHTAGS']\n",
    "\n",
    "#Create a dataframe from the list\n",
    "\n",
    "df = pd.DataFrame(data=tweetList, columns=columns_new)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nairobi_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_1.csv')\n",
    "data2=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_2.csv')\n",
    "data3=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_3.csv')\n",
    "data4=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_4.csv')\n",
    "data5=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_5.csv')\n",
    "data6=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_6.csv')\n",
    "data7=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_7.csv')\n",
    "\n",
    "\n",
    "new_df = pd.concat([data1, data2, data3, data4, data5, data6, data7])\n",
    "\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicateDFRow = new_df[new_df.duplicated()]\n",
    "print(duplicateDFRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "\n",
    "new_df.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''for col in new_df:\n",
    "    print(col)'''\n",
    "nairobi_final = new_df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nairobi_final.to_csv('nairobi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check for the max and min dates in the data frame\n",
    "#not correct as such in some instances\n",
    "\n",
    "print(f\" Data Available since {new_df.DATE.min()}\")\n",
    "print(f\" Data Available upto {new_df.DATE.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\" Maximum number of retweets {new_df.RETWEETS.max()}\")\n",
    "print(f\" Maximum number of favorites {new_df.FAVORITES.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#wordcloud\n",
    "\n",
    "wordcloud__ = WordCloud(\n",
    "                          background_color='yellow',\n",
    "                          stopwords=set(STOPWORDS),\n",
    "                          max_words=250,\n",
    "                          max_font_size=40, \n",
    "                          random_state=1705\n",
    "                         ).generate(str(new_df['TWEET'].dropna()))\n",
    "def cloud_plot(wordcloud):\n",
    "    fig = plt.figure(1, figsize=(20,15))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "cloud_plot(wordcloud__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of tweets according to dates\n",
    "\n",
    "df['DATE'] =  pd.to_datetime(new_df['DATE'])\n",
    "cnt_srs =new_df['DATE'].dt.date.value_counts()\n",
    "cnt_srs = cnt_srs.sort_index()\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Number of tweets', fontsize=12)\n",
    "plt.title(\"Number of tweets according to dates\")\n",
    "plt.show()"
   ]
  }
 ]
}