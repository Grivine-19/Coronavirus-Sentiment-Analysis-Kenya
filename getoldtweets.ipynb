{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit0854bf3467af411fb37e49bb5515948a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define global variables for the project\n",
    "\n",
    "'''the phrase to search for \n",
    "Can only search for string, not list or otherwise\n",
    "#Search words below were used only for the case of Nairobi\n",
    "#KomeshaCorona\n",
    "#COVID19KE\n",
    "#UHURUsToughChoices\n",
    "#UhuruAddress\n",
    "#staysafe\n",
    "#UhuruDontLiftLockdown\n",
    "#CurfewinKenya'''\n",
    "\n",
    "search_text = 'COVID_19'  \n",
    "\n",
    "since_date = '2019-11-01' #specifies the date to begin querying/searching from\n",
    "\n",
    "until_date = '2020-08-01' #specifies the date to end our query/search\n",
    "\n",
    "count = 100000 #specifies the number of tweets to fetch. Give a high value figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Creation of a Query Object**</center>\n",
    "\n",
    "#### *I will be using python classes; tweet, tweetManager and tweetCriteria of the GetOldTweets Library*\n",
    "\n",
    "#### *The search parameters to look out for that suit my purpose in this project are:*\n",
    "* *Text of the tweet*\n",
    "* *Location of the user-doesn't give the precise location of the tweet but a general location of the tweet since most users do not share the exact tweet location*\n",
    "* *Date of the tweet*\n",
    "* *Retweet Count-shows that most people resonate with the tweet*\n",
    "* *Favorited tweets*\n",
    "* *Hashtag-our search_text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Execute the code using python classes\n",
    "\n",
    "#search parameters to be used with the manager class\n",
    "\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(search_text).setSince(since_date)\\\n",
    "    .setUntil(until_date).setNear('Mombasa,Kenya').setMaxTweets(count)\n",
    "\n",
    "#List of objects get stored in tweets variable\n",
    "\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "#print(tweets + '\\n')\n",
    "\n",
    "#iterating through tweets list and storing them temporarily in the tweets variable.\n",
    "#get information and store it as a list inside tweetsList\n",
    "\n",
    "tweetList = [[tweet.id, tweet.date, tweet.text, tweet.geo, tweet.retweets, tweet.favorites, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "#print(tweetList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the columns for your dataframe\n",
    "\n",
    "columns_new = ['ID', 'DATE', 'TWEET', 'LOCATION', 'RETWEETS', 'FAVORITES', 'HASHTAGS']\n",
    "\n",
    "#Create a dataframe from the list\n",
    "\n",
    "df = pd.DataFrame(data=tweetList, columns=columns_new)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nairobi_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_1.csv')\n",
    "data2=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_2.csv')\n",
    "data3=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_3.csv')\n",
    "data4=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_4.csv')\n",
    "data5=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_5.csv')\n",
    "data6=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_6.csv')\n",
    "data7=pd.read_csv('/home/grivine/Desktop/Get_Old_Tweets/nairobi_7.csv')\n",
    "\n",
    "\n",
    "new_df = pd.concat([data1, data2, data3, data4, data5, data6, data7])\n",
    "\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicateDFRow = new_df[new_df.duplicated()]\n",
    "print(duplicateDFRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''for col in new_df:\n",
    "    print(col)'''\n",
    "nairobi_final = new_df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check for the max and min dates in the data frame\n",
    "#not correct as such in some instances\n",
    "\n",
    "print(f\" Data Available since {new_df.DATE.min()}\")\n",
    "print(f\" Data Available upto {new_df.DATE.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\" Maximum number of retweets {new_df.RETWEETS.max()}\")\n",
    "print(f\" Maximum number of favorites {new_df.FAVORITES.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nairobi_final.to_csv('nairobi.csv')"
   ]
  }
 ]
}